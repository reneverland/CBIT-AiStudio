# BaiduCBIT - åŸºäºComfyUIçš„ä¼ä¸šçº§AIå›¾åƒç”Ÿæˆå¹³å°

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/Python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![Flask](https://img.shields.io/badge/Flask-3.0+-green.svg)](https://flask.palletsprojects.com/)
[![ComfyUI](https://img.shields.io/badge/ComfyUI-Latest-orange.svg)](https://github.com/comfyanonymous/ComfyUI)
[![Flux](https://img.shields.io/badge/Flux-1.0%20Dev-purple.svg)](https://huggingface.co/black-forest-labs/FLUX.1-dev)

## ğŸ¬ æœ€æ–°æ¼”ç¤º

### ç•Œé¢å±•ç¤ºå½•å± (2025-10-02)
> **æœ€æ–°ä¼˜åŒ–ç•Œé¢æ¼”ç¤º** - å±•ç¤ºäº†å…¨æ–°çš„ç”¨æˆ·å‹å¥½ç•Œé¢è®¾è®¡å’Œä¸€é”®ç”ŸæˆåŠŸèƒ½

ğŸ“¹ **æ¼”ç¤ºè§†é¢‘**: [`showcase_instruction.mov`](https://cbit.cuhk.edu.cn/files/showcase_instruction.mov)

> æ³¨æ„ï¼šç”±äºæ–‡ä»¶å¤§å°é™åˆ¶ï¼Œå½•å±æ–‡ä»¶æœªåŒ…å«åœ¨Gitä»“åº“ä¸­ã€‚å¦‚éœ€æŸ¥çœ‹æ¼”ç¤ºï¼Œè¯·è”ç³»å¼€å‘è€…è·å–ã€‚

**ä¸»è¦ç‰¹æ€§æ¼”ç¤º**:
- ğŸš€ **ä¸€é”®ç”Ÿæˆ**: ç®€åŒ–çš„æ“ä½œæµç¨‹ï¼Œè¾“å…¥æç¤ºè¯å³å¯å¿«é€Ÿç”Ÿæˆ
- ğŸ¨ **ç²¾é€‰æ¨¡æ¿**: äººåƒæ‘„å½±ã€ç”Ÿæ´»åœºæ™¯ã€è‰ºæœ¯é£æ ¼ç­‰ä¸“ä¸šé¢„è®¾
- âš™ï¸ **æ™ºèƒ½è®¾ç½®**: å¯æŠ˜å çš„é«˜çº§å‚æ•°é…ç½®
- ğŸŒŸ **ç°ä»£ç•Œé¢**: ç»ç’ƒæ‹Ÿæ€è®¾è®¡ï¼Œå“åº”å¼å¸ƒå±€
- ğŸ”„ **å®æ—¶åé¦ˆ**: ç”Ÿæˆè¿›åº¦å’ŒçŠ¶æ€å®æ—¶æ˜¾ç¤º

## è‡´è°¢

æ„Ÿè°¢**ç™¾åº¦æ·±åœ³å¹¿å‘ŠæŠ•æ”¾éƒ¨é—¨**å¯¹æœ¬é¡¹ç›®çš„å¤§åŠ›æ”¯æŒä¸è´¡çŒ®ï¼ä»–ä»¬çš„ä¸“ä¸šæŒ‡å¯¼å’Œèµ„æºæŠ•å…¥ä¸ºé¡¹ç›®çš„æˆåŠŸå®æ–½æä¾›äº†é‡è¦ä¿éšœã€‚

Special thanks to **Baidu Shenzhen Advertising Department** for their tremendous support and contribution to this project! Their professional guidance and resource investment have provided crucial support for the successful implementation of this project.

---

## é¡¹ç›®æ¦‚è¿°

BaiduCBITæ˜¯ä¸€ä¸ªåŸºäºComfyUIçš„ä¼ä¸šçº§AIå›¾åƒç”Ÿæˆå¹³å°ï¼Œä¸“æ³¨äºçœŸäººçº§åˆ«çš„é«˜è´¨é‡å›¾åƒç”Ÿæˆã€‚è¯¥å¹³å°é‡‡ç”¨å…ˆè¿›çš„Fluxæ¨¡å‹æ¶æ„ï¼Œç»“åˆå¤šç§AIå¢å¼ºæŠ€æœ¯ï¼Œå®ç°äº†ä»æ–‡æœ¬æè¿°åˆ°çœŸå®æ„Ÿå›¾åƒçš„ç«¯åˆ°ç«¯ç”Ÿæˆæµç¨‹ã€‚

## æ ¸å¿ƒæŠ€æœ¯æ¶æ„

### 1. æ·±åº¦å­¦ä¹ æ¨¡å‹æ ˆ

#### ä¸»æ¨¡å‹æ¶æ„
- **Flux 1.0 Dev Model**: åŸºäºDiffusion Transformeræ¶æ„çš„æœ€æ–°ç”Ÿæˆæ¨¡å‹
  - æ¨¡å‹ç²¾åº¦: FP8_E4M3FNé‡åŒ–ï¼Œä¼˜åŒ–å†…å­˜ä½¿ç”¨
  - å‚æ•°è§„æ¨¡: 12Bå‚æ•°ï¼Œæ”¯æŒé«˜åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆ
  - æ½œåœ¨ç©ºé—´: 8xå‹ç¼©æ¯”çš„VAEç¼–ç å™¨

#### æ–‡æœ¬ç¼–ç å™¨
- **Dual-CLIP Architecture**: 
  - CLIP-L: å¤„ç†è§†è§‰-è¯­è¨€ç†è§£
  - T5-XXL FP16: å¢å¼ºæ–‡æœ¬è¯­ä¹‰ç†è§£èƒ½åŠ›
  - æ”¯æŒå¤šè¯­è¨€è¾“å…¥å’Œè¯­ä¹‰å¯¹é½

#### LoRAå¾®è°ƒæ¨¡å—
- **æ‰‹éƒ¨ä¿®å¤LoRA**: ä¸“é—¨ä¼˜åŒ–äººä½“æ‰‹éƒ¨ç»†èŠ‚ç”Ÿæˆ
- **åæ¨¡ç³ŠLoRA**: æå‡å›¾åƒé”åº¦å’Œç»†èŠ‚ä¿çœŸåº¦
- **çœŸå®æ„Ÿå¢å¼ºLoRA**: ä¼˜åŒ–äººåƒçœŸå®æ„Ÿå’Œçš®è‚¤è´¨æ„Ÿ
- **Fluxå¢å¼ºLoRA**: æ¨¡å‹æ€§èƒ½æ•´ä½“æå‡

### 2. é«˜çº§é‡‡æ ·ç®—æ³•

#### åŒé˜¶æ®µé‡‡æ ·ç­–ç•¥
```
ç¬¬ä¸€é˜¶æ®µ: é«˜å™ªå£°å»å™ª (Sigma Split: 0.7)
â”œâ”€â”€ å™ªå£°æ³¨å…¥å¼ºåº¦: 0.85
â”œâ”€â”€ é‡‡æ ·å™¨: Euler Ancestral + Advanced Lying Sigma
â””â”€â”€ æ­¥æ•°: 30æ­¥ (70%é˜¶æ®µ)

ç¬¬äºŒé˜¶æ®µ: ç²¾ç»†åŒ–å¤„ç† (Sigma Split: 0.3)
â”œâ”€â”€ ç¦ç”¨å™ªå£°æ³¨å…¥
â”œâ”€â”€ æ½œåœ¨ç©ºé—´æ’å€¼: 0.35æ¯”ä¾‹
â””â”€â”€ ç»†èŠ‚å¢å¼ºé‡‡æ ·
```

#### è‡ªé€‚åº”å¼•å¯¼æœºåˆ¶
- **Flux Guidance**: åŠ¨æ€è°ƒæ•´ç”Ÿæˆéµå¾ªåº¦ (èŒƒå›´: 2.0-5.0)
- **ControlNet Integration**: æ”¯æŒç»“æ„åŒ–æ§åˆ¶ç”Ÿæˆ
- **Negative Prompting**: æ™ºèƒ½è´Ÿé¢æç¤ºè¯è¿‡æ»¤

### 3. å›¾åƒåå¤„ç†ç®¡çº¿

#### å¤šå±‚æ¬¡å¢å¼ºæµç¨‹
```
åŸå§‹è¾“å‡º â†’ é”åŒ–å¤„ç† â†’ èƒ¶ç‰‡é¢—ç²’ â†’ CAé”åŒ– â†’ æœ€ç»ˆè¾“å‡º
    â†“           â†“         â†“        â†“
  VAEè§£ç     ImageSharpen  FilmGrain  CASharp
```

- **è‡ªé€‚åº”é”åŒ–**: åŸºäºå†…å®¹çš„æ™ºèƒ½é”åŒ–ç®—æ³•
- **èƒ¶ç‰‡é¢—ç²’æ¨¡æ‹Ÿ**: å¢åŠ çœŸå®æ‘„å½±è´¨æ„Ÿ
- **è‰²å·®æ ¡æ­£**: æ¶ˆé™¤è‰²å½©åç§»ï¼Œæå‡è‰²å½©å‡†ç¡®åº¦

### 4. åˆ†å¸ƒå¼æ¶æ„è®¾è®¡

#### ç”Ÿäº§ç¯å¢ƒæ¶æ„
```
Webå‰ç«¯ â†’ Flaskåº”ç”¨ â†’ ComfyUIå¼•æ“ â†’ GPUé›†ç¾¤
    â†“         â†“          â†“           â†“
  ç”¨æˆ·ç•Œé¢   APIç½‘å…³    å·¥ä½œæµå¼•æ“   æ¨¡å‹æ¨ç†
```

#### æœ¬åœ°å¼€å‘æ¶æ„
```
å¼€å‘ç¯å¢ƒ â†’ æ¨ç†æœåŠ¡ â†’ è¿œç¨‹ComfyUI â†’ äº‘ç«¯GPU
    â†“         â†“          â†“          â†“
  æœ¬åœ°è°ƒè¯•   æœåŠ¡ä»£ç†    APIè½¬å‘    æ¨¡å‹è®¡ç®—
```

## æŠ€æœ¯ç‰¹æ€§

### çœŸäººçº§å›¾åƒç”Ÿæˆèƒ½åŠ›

#### 1. é«˜ä¿çœŸäººåƒç”Ÿæˆ
- **çš®è‚¤è´¨æ„Ÿ**: åŸºäºç‰©ç†çš„çš®è‚¤æ¸²æŸ“ï¼Œæ”¯æŒä¸åŒè‚¤è‰²å’Œå¹´é¾„
- **é¢éƒ¨ç»†èŠ‚**: ç²¾ç¡®çš„äº”å®˜æ¯”ä¾‹å’Œè¡¨æƒ…æ•æ‰
- **å‘ä¸ç»†èŠ‚**: å•æ ¹å‘ä¸çº§åˆ«çš„ç»†èŠ‚è¿˜åŸ
- **å…‰å½±æ•ˆæœ**: çœŸå®çš„å…‰ç…§æ¨¡æ‹Ÿå’Œé˜´å½±æŠ•å°„

#### 2. èº«ä½“ç»“æ„ä¼˜åŒ–
- **æ‰‹éƒ¨ä¿®å¤**: ä¸“é—¨çš„LoRAæ¨¡å‹è§£å†³æ‰‹éƒ¨ç•¸å˜é—®é¢˜
- **èº«ä½“æ¯”ä¾‹**: ç¬¦åˆäººä½“å·¥ç¨‹å­¦çš„æ¯”ä¾‹æ§åˆ¶
- **æœè£…ç»†èŠ‚**: é¢æ–™è´¨æ„Ÿå’Œè¤¶çš±çš„çœŸå®æ¨¡æ‹Ÿ
- **å§¿æ€è‡ªç„¶**: è‡ªç„¶çš„äººä½“å§¿æ€å’ŒåŠ¨ä½œè¡¨ç°

#### 3. åœºæ™¯èåˆæŠ€æœ¯
- **ç¯å¢ƒå…‰ç…§**: ä¸åœºæ™¯å…‰ç…§çš„æ— ç¼èåˆ
- **æ™¯æ·±æ•ˆæœ**: ä¸“ä¸šæ‘„å½±çº§åˆ«çš„æ™¯æ·±æ§åˆ¶
- **æè´¨åå°„**: çœŸå®çš„æè´¨å…‰å­¦ç‰¹æ€§
- **å¤§æ°”é€è§†**: è·ç¦»æ„Ÿå’Œç©ºé—´å±‚æ¬¡çš„å‡†ç¡®è¡¨ç°

### å¤šè¯­è¨€æ™ºèƒ½ç¿»è¯‘

#### ç¿»è¯‘å¼•æ“é›†æˆ
- **Bing Translator API**: æ”¯æŒ100+è¯­è¨€çš„é«˜è´¨é‡ç¿»è¯‘
- **è¯­ä¹‰å¢å¼º**: è‡ªåŠ¨æ·»åŠ æ‘„å½±å’Œè´¨é‡ç›¸å…³çš„ä¸“ä¸šæœ¯è¯­
- **ä¸Šä¸‹æ–‡ç†è§£**: åŸºäºåœºæ™¯çš„æ™ºèƒ½è¯æ±‡é€‰æ‹©
- **é£æ ¼é€‚é…**: æ ¹æ®ç”Ÿæˆé£æ ¼è°ƒæ•´æç¤ºè¯è¡¨è¾¾

#### æç¤ºè¯ä¼˜åŒ–
```python
åŸå§‹è¾“å…¥: "ä¸€ä½ç¾ä¸½çš„ä¸­å›½å¥³æ€§åœ¨å’–å•¡é¦†è¯»ä¹¦"
â†“ ç¿»è¯‘å¤„ç†
æ™ºèƒ½è¾“å‡º: "A beautiful Chinese woman reading in a coffee shop, 
          high quality, detailed, realistic, professional photography, 
          sharp focus, natural lighting, lifestyle photo"
```

### ControlNetç²¾ç¡®æ§åˆ¶

#### æ”¯æŒçš„æ§åˆ¶ç±»å‹
- **Tile Control**: åŸºäºå‚è€ƒå›¾åƒçš„ç»“æ„æ§åˆ¶
- **Depth Control**: æ·±åº¦å›¾å¼•å¯¼çš„ç©ºé—´å¸ƒå±€
- **Pose Control**: äººä½“å§¿æ€çš„ç²¾ç¡®æ§åˆ¶
- **Edge Control**: è¾¹ç¼˜æ£€æµ‹å¼•å¯¼çš„è½®å»“ç”Ÿæˆ

#### é¢„å¤„ç†ç®¡çº¿
- **AIO Preprocessor**: è‡ªåŠ¨é€‰æ‹©æœ€é€‚åˆçš„é¢„å¤„ç†å™¨
- **Union ControlNet**: å¤šç§æ§åˆ¶ç±»å‹çš„ç»Ÿä¸€å¤„ç†
- **å¼ºåº¦è°ƒèŠ‚**: 0.0-1.0èŒƒå›´çš„ç²¾ç»†æ§åˆ¶å¼ºåº¦è°ƒèŠ‚

## éƒ¨ç½²æ¶æ„ä¼˜åŠ¿

### ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

#### ä¼˜åŠ¿ç‰¹æ€§
1. **é«˜æ€§èƒ½**: ç›´è¿ComfyUIï¼Œå‡å°‘ç½‘ç»œå»¶è¿Ÿ
2. **ç¨³å®šæ€§**: æœ¬åœ°åŒ–éƒ¨ç½²ï¼Œé¿å…å¤–éƒ¨ä¾èµ–
3. **å®‰å…¨æ€§**: æ•°æ®ä¸å‡ºæœ¬åœ°ï¼Œä¿æŠ¤ç”¨æˆ·éšç§
4. **å¯æ‰©å±•**: æ”¯æŒGPUé›†ç¾¤å’Œè´Ÿè½½å‡è¡¡
5. **æˆæœ¬æ•ˆç›Š**: ä¸€æ¬¡éƒ¨ç½²ï¼Œé•¿æœŸä½¿ç”¨

#### æŠ€æœ¯æ ˆ
```
å‰ç«¯: Flask + Jinja2 + JavaScript
åç«¯: Python 3.12 + SQLAlchemy + MySQL
AIå¼•æ“: ComfyUI + PyTorch + CUDA 12.4
éƒ¨ç½²: Gunicorn + Nginx + Docker (å¯é€‰)
```

### æœ¬åœ°å¼€å‘ç¯å¢ƒ

#### ä¼˜åŠ¿ç‰¹æ€§
1. **å¿«é€Ÿè¿­ä»£**: æœ¬åœ°å¼€å‘ï¼Œå®æ—¶è°ƒè¯•
2. **èµ„æºå…±äº«**: é€šè¿‡æ¨ç†æœåŠ¡å…±äº«GPUèµ„æº
3. **ç¯å¢ƒéš”ç¦»**: å¼€å‘ç¯å¢ƒä¸ç”Ÿäº§ç¯å¢ƒåˆ†ç¦»
4. **æˆæœ¬æ§åˆ¶**: æŒ‰éœ€ä½¿ç”¨äº‘ç«¯GPUèµ„æº
5. **å›¢é˜Ÿåä½œ**: å¤šäººå…±äº«åŒä¸€æ¨ç†æœåŠ¡

#### æ¶æ„ç‰¹ç‚¹
```
æœ¬åœ°Flaskåº”ç”¨ â†â†’ æ¨ç†æœåŠ¡ä»£ç† â†â†’ è¿œç¨‹ComfyUIé›†ç¾¤
      â†“                â†“                â†“
   ç•Œé¢å¼€å‘         APIè½¬å‘           æ¨¡å‹è®¡ç®—
   é€»è¾‘è°ƒè¯•         è´Ÿè½½å‡è¡¡           èµ„æºç®¡ç†
   å¿«é€Ÿæµ‹è¯•         é”™è¯¯å¤„ç†           ç»“æœç¼“å­˜
```

## æ€§èƒ½æŒ‡æ ‡

### å›¾åƒç”Ÿæˆæ€§èƒ½
- **åˆ†è¾¨ç‡**: æ”¯æŒ896x1392åˆ°2048x2048
- **ç”Ÿæˆæ—¶é—´**: 30æ­¥é‡‡æ ·çº¦15-30ç§’ (RTX 4090)
- **å†…å­˜å ç”¨**: 8GB VRAM (FP8é‡åŒ–)
- **æ‰¹å¤„ç†**: æ”¯æŒæ‰¹é‡ç”Ÿæˆå’Œé˜Ÿåˆ—ç®¡ç†

### ç³»ç»Ÿæ€§èƒ½
- **å¹¶å‘å¤„ç†**: æ”¯æŒå¤šç”¨æˆ·åŒæ—¶ç”Ÿæˆ
- **é˜Ÿåˆ—ç®¡ç†**: æ™ºèƒ½ä»»åŠ¡è°ƒåº¦å’Œä¼˜å…ˆçº§æ§åˆ¶
- **ç¼“å­˜æœºåˆ¶**: æ¨¡å‹ç¼“å­˜å’Œç»“æœç¼“å­˜
- **ç›‘æ§å‘Šè­¦**: å®æ—¶æ€§èƒ½ç›‘æ§å’Œå¼‚å¸¸å‘Šè­¦

## å·¥ä½œæµé…ç½®

### æ ¸å¿ƒå·¥ä½œæµæ–‡ä»¶
- `fluxfinalV1.json`: å®Œæ•´çš„çœŸäººç”Ÿå›¾å·¥ä½œæµ
- `flux819translate.json`: å¸¦ç¿»è¯‘åŠŸèƒ½çš„å·¥ä½œæµ
- `flux820withouttran.json`: æ— ç¿»è¯‘çš„ä¼˜åŒ–å·¥ä½œæµ

### å‚æ•°é…ç½®
```json
{
  "model": "flux1-dev.safetensors",
  "scheduler": "euler_ancestral",
  "steps": 30,
  "guidance": 3.0,
  "resolution": "896x1392",
  "lora_stack": ["hand_fix", "antiblur", "realistic"],
  "post_processing": ["sharpen", "film_grain", "ca_sharp"]
}
```

## å®‰è£…å’Œéƒ¨ç½²

### ç³»ç»Ÿè¦æ±‚
- **æ“ä½œç³»ç»Ÿ**: Linux (Ubuntu 20.04+æ¨è)
- **Python**: 3.12+
- **GPU**: NVIDIA RTX 3080+ (8GB+ VRAM)
- **CUDA**: 12.4+
- **å†…å­˜**: 16GB+ RAM
- **å­˜å‚¨**: 100GB+ å¯ç”¨ç©ºé—´

### å¿«é€Ÿéƒ¨ç½²
```bash
# 1. å…‹éš†é¡¹ç›®
git clone <repository-url>
cd baiducbit

# 2. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 3. åˆå§‹åŒ–é…ç½®
cp env.example .env
# ç¼–è¾‘.envæ–‡ä»¶é…ç½®æ•°æ®åº“å’ŒæœåŠ¡åœ°å€

# 4. å¯åŠ¨æœåŠ¡
python run.py
```

### ç”Ÿäº§éƒ¨ç½²
```bash
# ä½¿ç”¨Gunicornå¯åŠ¨
gunicorn -c gunicorn_conf.py app:app

# æˆ–ä½¿ç”¨å¯åŠ¨è„šæœ¬
./scripts/start_baiducbit.sh
```

## APIæ¥å£

### æ ¸å¿ƒæ¥å£
- `POST /api/generate`: å›¾åƒç”Ÿæˆ
- `GET /api/result`: è·å–ç”Ÿæˆç»“æœ
- `POST /api/upload`: æ–‡ä»¶ä¸Šä¼ 
- `GET /api/queue`: é˜Ÿåˆ—çŠ¶æ€æŸ¥è¯¢

### ç¤ºä¾‹è¯·æ±‚
```python
import requests

# ç”Ÿæˆå›¾åƒ
response = requests.post('/api/generate', json={
    'mode': 'translate',
    'original_text': 'ä¸€ä½ç¾ä¸½çš„å¥³æ€§åœ¨èŠ±å›­é‡Œ',
    'width': 896,
    'height': 1392,
    'steps': 30,
    'guidance': 3.0
})

# è·å–ç»“æœ
result = requests.get(f'/api/result?prompt_id={response.json()["prompt_id"]}')
```

## å¼€å‘è·¯çº¿å›¾

### å·²å®ŒæˆåŠŸèƒ½
- âœ… Fluxæ¨¡å‹é›†æˆå’Œä¼˜åŒ–
- âœ… å¤šè¯­è¨€ç¿»è¯‘æ”¯æŒ
- âœ… ControlNetæ§åˆ¶ç”Ÿæˆ
- âœ… LoRAå¾®è°ƒé›†æˆ
- âœ… åŒç¯å¢ƒéƒ¨ç½²æ¶æ„
- âœ… Webç•Œé¢å’ŒAPI

### å¼€å‘ä¸­åŠŸèƒ½
- ğŸ”„ è§†é¢‘ç”Ÿæˆé›†æˆ
- ğŸ”„ æ‰¹é‡å¤„ç†ä¼˜åŒ–
- ğŸ”„ æ¨¡å‹çƒ­æ›´æ–°
- ğŸ”„ é«˜çº§ç¼“å­˜æœºåˆ¶

### è®¡åˆ’åŠŸèƒ½
- ğŸ“‹ å¤šæ¨¡å‹æ”¯æŒ (SDXL, SD3.5)
- ğŸ“‹ å®æ—¶ç”Ÿæˆé¢„è§ˆ
- ğŸ“‹ ç”¨æˆ·æƒé™ç®¡ç†
- ğŸ“‹ APIé™æµå’Œè®¡è´¹
- ğŸ“‹ åˆ†å¸ƒå¼GPUé›†ç¾¤

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ï¼Œè¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤Issueå’ŒPull Requestã€‚è¯·ç¡®ä¿ï¼š
1. ä»£ç ç¬¦åˆPEP 8è§„èŒƒ
2. æ·»åŠ é€‚å½“çš„æµ‹è¯•ç”¨ä¾‹
3. æ›´æ–°ç›¸å…³æ–‡æ¡£
4. æäº¤å‰è¿è¡Œå®Œæ•´æµ‹è¯•

## è”ç³»æ–¹å¼

- **é¡¹ç›®ç»´æŠ¤è€…**: BaiduCBIT Team
- **å¼€å‘è€…**: [@reneverland](https://github.com/reneverland) - Full-stack Developer Â· AI Fine-tuning Â· Multimodal Systems
- **GitHubä»“åº“**: [https://github.com/reneverland/CBIT-AiStudio](https://github.com/reneverland/CBIT-AiStudio)
- **æŠ€æœ¯æ”¯æŒ**: é€šè¿‡GitHub Issuesæäº¤é—®é¢˜å’Œå»ºè®®
- **æ–‡æ¡£æ›´æ–°**: 2025å¹´10æœˆ

---

*æœ¬æ–‡æ¡£æŒç»­æ›´æ–°ä¸­ï¼Œæœ€æ–°ç‰ˆæœ¬è¯·æŸ¥çœ‹é¡¹ç›®ä»“åº“ã€‚*

---

# BaiduCBIT - Enterprise-Level AI Image Generation Platform Based on ComfyUI

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/Python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![Flask](https://img.shields.io/badge/Flask-3.0+-green.svg)](https://flask.palletsprojects.com/)
[![ComfyUI](https://img.shields.io/badge/ComfyUI-Latest-orange.svg)](https://github.com/comfyanonymous/ComfyUI)
[![Flux](https://img.shields.io/badge/Flux-1.0%20Dev-purple.svg)](https://huggingface.co/black-forest-labs/FLUX.1-dev)

## ğŸ¬ Latest Demo

### UI Showcase Recording (2025-10-02)
> **Latest Optimized Interface Demo** - Showcasing the new user-friendly interface design and one-click generation functionality

ğŸ“¹ **Demo Video**: [`showcase_instruction.mov`](https://cbit.cuhk.edu.cn/files/showcase_instruction.mov)

> Note: Due to file size limitations, the demo video is not included in the Git repository. Please contact the developer for access.

**Key Features Demonstrated**:
- ğŸš€ **One-Click Generation**: Simplified workflow, generate images by simply entering prompts
- ğŸ¨ **Featured Templates**: Professional presets for portrait photography, lifestyle scenes, and artistic styles
- âš™ï¸ **Smart Settings**: Collapsible advanced parameter configuration
- ğŸŒŸ **Modern Interface**: Glassmorphism design with responsive layout
- ğŸ”„ **Real-time Feedback**: Live generation progress and status updates

## Project Overview

BaiduCBIT is an enterprise-level AI image generation platform based on ComfyUI, focusing on photorealistic human image generation. The platform adopts advanced Flux model architecture combined with various AI enhancement technologies to achieve end-to-end generation from text descriptions to realistic images.

## Core Technical Architecture

### 1. Deep Learning Model Stack

#### Main Model Architecture
- **Flux 1.0 Dev Model**: Latest generative model based on Diffusion Transformer architecture
  - Model Precision: FP8_E4M3FN quantization for optimized memory usage
  - Parameter Scale: 12B parameters supporting high-resolution image generation
  - Latent Space: VAE encoder with 8x compression ratio

#### Text Encoders
- **Dual-CLIP Architecture**: 
  - CLIP-L: Handles visual-language understanding
  - T5-XXL FP16: Enhanced text semantic understanding capability
  - Supports multilingual input and semantic alignment

#### LoRA Fine-tuning Modules
- **Hand Repair LoRA**: Specialized optimization for human hand detail generation
- **Anti-blur LoRA**: Improves image sharpness and detail fidelity
- **Realism Enhancement LoRA**: Optimizes portrait realism and skin texture
- **Flux Enhancement LoRA**: Overall model performance improvement

### 2. Advanced Sampling Algorithms

#### Dual-Stage Sampling Strategy
```
Stage 1: High-noise Denoising (Sigma Split: 0.7)
â”œâ”€â”€ Noise Injection Strength: 0.85
â”œâ”€â”€ Sampler: Euler Ancestral + Advanced Lying Sigma
â””â”€â”€ Steps: 30 steps (70% stage)

Stage 2: Fine-tuning Processing (Sigma Split: 0.3)
â”œâ”€â”€ Disable Noise Injection
â”œâ”€â”€ Latent Space Interpolation: 0.35 ratio
â””â”€â”€ Detail Enhancement Sampling
```

#### Adaptive Guidance Mechanism
- **Flux Guidance**: Dynamic adjustment of generation adherence (Range: 2.0-5.0)
- **ControlNet Integration**: Supports structured control generation
- **Negative Prompting**: Intelligent negative prompt filtering

### 3. Image Post-processing Pipeline

#### Multi-level Enhancement Process
```
Raw Output â†’ Sharpening â†’ Film Grain â†’ CA Sharpening â†’ Final Output
    â†“           â†“         â†“        â†“
  VAE Decode  ImageSharpen  FilmGrain  CASharp
```

- **Adaptive Sharpening**: Content-based intelligent sharpening algorithm
- **Film Grain Simulation**: Adds realistic photographic texture
- **Chromatic Aberration Correction**: Eliminates color shift, improves color accuracy

### 4. Distributed Architecture Design

#### Production Environment Architecture
```
Web Frontend â†’ Flask App â†’ ComfyUI Engine â†’ GPU Cluster
    â†“         â†“          â†“           â†“
  User Interface  API Gateway  Workflow Engine  Model Inference
```

#### Local Development Architecture
```
Dev Environment â†’ Inference Service â†’ Remote ComfyUI â†’ Cloud GPU
    â†“         â†“          â†“          â†“
  Local Debug   Service Proxy    API Forward    Model Computation
```

## Technical Features

### Photorealistic Human Image Generation

#### 1. High-Fidelity Portrait Generation
- **Skin Texture**: Physics-based skin rendering supporting different skin tones and ages
- **Facial Details**: Precise facial proportions and expression capture
- **Hair Details**: Individual hair strand level detail restoration
- **Lighting Effects**: Realistic lighting simulation and shadow casting

#### 2. Body Structure Optimization
- **Hand Repair**: Specialized LoRA model solving hand deformation issues
- **Body Proportions**: Human ergonomics-compliant proportion control
- **Clothing Details**: Realistic fabric texture and wrinkle simulation
- **Natural Poses**: Natural human postures and movement expressions

#### 3. Scene Integration Technology
- **Environmental Lighting**: Seamless integration with scene lighting
- **Depth of Field**: Professional photography-level depth control
- **Material Reflection**: Realistic material optical properties
- **Atmospheric Perspective**: Accurate distance perception and spatial layering

### Multilingual Intelligent Translation

#### Translation Engine Integration
- **Bing Translator API**: High-quality translation supporting 100+ languages
- **Semantic Enhancement**: Automatic addition of photography and quality-related professional terms
- **Context Understanding**: Intelligent vocabulary selection based on scenes
- **Style Adaptation**: Adjusts prompt expression according to generation style

#### Prompt Optimization
```python
Original Input: "ä¸€ä½ç¾ä¸½çš„ä¸­å›½å¥³æ€§åœ¨å’–å•¡é¦†è¯»ä¹¦"
â†“ Translation Processing
Smart Output: "A beautiful Chinese woman reading in a coffee shop, 
          high quality, detailed, realistic, professional photography, 
          sharp focus, natural lighting, lifestyle photo"
```

### ControlNet Precise Control

#### Supported Control Types
- **Tile Control**: Structure control based on reference images
- **Depth Control**: Spatial layout guided by depth maps
- **Pose Control**: Precise control of human poses
- **Edge Control**: Contour generation guided by edge detection

#### Preprocessing Pipeline
- **AIO Preprocessor**: Automatically selects the most suitable preprocessor
- **Union ControlNet**: Unified processing of multiple control types
- **Strength Adjustment**: Fine control strength adjustment in 0.0-1.0 range

## Deployment Architecture Advantages

### Production Environment Deployment

#### Advantage Features
1. **High Performance**: Direct ComfyUI connection, reduced network latency
2. **Stability**: Local deployment, avoiding external dependencies
3. **Security**: Data stays local, protecting user privacy
4. **Scalability**: Supports GPU clusters and load balancing
5. **Cost Effectiveness**: One-time deployment, long-term use

#### Technology Stack
```
Frontend: Flask + Jinja2 + JavaScript
Backend: Python 3.12 + SQLAlchemy + MySQL
AI Engine: ComfyUI + PyTorch + CUDA 12.4
Deployment: Gunicorn + Nginx + Docker (optional)
```

### Local Development Environment

#### Advantage Features
1. **Rapid Iteration**: Local development, real-time debugging
2. **Resource Sharing**: Share GPU resources through inference service
3. **Environment Isolation**: Separation of development and production environments
4. **Cost Control**: On-demand use of cloud GPU resources
5. **Team Collaboration**: Multiple people sharing the same inference service

#### Architecture Features
```
Local Flask App â†â†’ Inference Service Proxy â†â†’ Remote ComfyUI Cluster
      â†“                â†“                â†“
   UI Development    API Forwarding    Model Computation
   Logic Debugging   Load Balancing    Resource Management
   Quick Testing     Error Handling    Result Caching
```

## Performance Metrics

### Image Generation Performance
- **Resolution**: Supports 896x1392 to 2048x2048
- **Generation Time**: 30-step sampling approximately 15-30 seconds (RTX 4090)
- **Memory Usage**: 8GB VRAM (FP8 quantization)
- **Batch Processing**: Supports batch generation and queue management

### System Performance
- **Concurrent Processing**: Supports multi-user simultaneous generation
- **Queue Management**: Intelligent task scheduling and priority control
- **Caching Mechanism**: Model caching and result caching
- **Monitoring & Alerting**: Real-time performance monitoring and exception alerting

## Workflow Configuration

### Core Workflow Files
- `fluxfinalV1.json`: Complete photorealistic image generation workflow
- `flux819translate.json`: Workflow with translation functionality
- `flux820withouttran.json`: Optimized workflow without translation

### Parameter Configuration
```json
{
  "model": "flux1-dev.safetensors",
  "scheduler": "euler_ancestral",
  "steps": 30,
  "guidance": 3.0,
  "resolution": "896x1392",
  "lora_stack": ["hand_fix", "antiblur", "realistic"],
  "post_processing": ["sharpen", "film_grain", "ca_sharp"]
}
```

## Installation and Deployment

### System Requirements
- **Operating System**: Linux (Ubuntu 20.04+ recommended)
- **Python**: 3.12+
- **GPU**: NVIDIA RTX 3080+ (8GB+ VRAM)
- **CUDA**: 12.4+
- **Memory**: 16GB+ RAM
- **Storage**: 100GB+ available space

### Quick Deployment
```bash
# 1. Clone project
git clone <repository-url>
cd baiducbit

# 2. Install dependencies
pip install -r requirements.txt

# 3. Initialize configuration
cp env.example .env
# Edit .env file to configure database and service addresses

# 4. Start service
python run.py
```

### Production Deployment
```bash
# Start with Gunicorn
gunicorn -c gunicorn_conf.py app:app

# Or use startup script
./scripts/start_baiducbit.sh
```

## API Interfaces

### Core Interfaces
- `POST /api/generate`: Image generation
- `GET /api/result`: Get generation results
- `POST /api/upload`: File upload
- `GET /api/queue`: Queue status query

### Example Request
```python
import requests

# Generate image
response = requests.post('/api/generate', json={
    'mode': 'translate',
    'original_text': 'ä¸€ä½ç¾ä¸½çš„å¥³æ€§åœ¨èŠ±å›­é‡Œ',
    'width': 896,
    'height': 1392,
    'steps': 30,
    'guidance': 3.0
})

# Get result
result = requests.get(f'/api/result?prompt_id={response.json()["prompt_id"]}')
```

## Development Roadmap

### Completed Features
- âœ… Flux model integration and optimization
- âœ… Multilingual translation support
- âœ… ControlNet control generation
- âœ… LoRA fine-tuning integration
- âœ… Dual-environment deployment architecture
- âœ… Web interface and API

### Features in Development
- ğŸ”„ Video generation integration
- ğŸ”„ Batch processing optimization
- ğŸ”„ Model hot updates
- ğŸ”„ Advanced caching mechanism

### Planned Features
- ğŸ“‹ Multi-model support (SDXL, SD3.5)
- ğŸ“‹ Real-time generation preview
- ğŸ“‹ User permission management
- ğŸ“‹ API rate limiting and billing
- ğŸ“‹ Distributed GPU cluster

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## Contributing Guidelines

Issues and Pull Requests are welcome. Please ensure:
1. Code follows PEP 8 standards
2. Add appropriate test cases
3. Update relevant documentation
4. Run complete tests before submission

## Contact Information

- **Project Maintainer**: BaiduCBIT Team
- **Developer**: [@reneverland](https://github.com/reneverland) - Full-stack Developer Â· AI Fine-tuning Â· Multimodal Systems
- **GitHub Repository**: [https://github.com/reneverland/CBIT-AiStudio](https://github.com/reneverland/CBIT-AiStudio)
- **Technical Support**: Submit issues and suggestions via GitHub Issues
- **Documentation Updated**: October 2025

---

*This document is continuously updated. Please check the project repository for the latest version.*
